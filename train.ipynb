{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from networks.unet import Unet\n",
    "\n",
    "from utils.batch_generator import BatchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "VAL_BATCH = 10\n",
    "IMG_ROWS, IMG_COLS = 256, 256\n",
    "NB_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_categorical(masks, batch_size=1):\n",
    "    masks = to_categorical(masks, 2)\n",
    "    masks = np.reshape(\n",
    "        masks,\n",
    "        (\n",
    "            batch_size, IMG_COLS * IMG_ROWS, 2\n",
    "        )\n",
    "    )\n",
    "    return masks.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossValidateCallback(Callback):\n",
    "\n",
    "    def __init__(self, batch_generator, results_file):\n",
    "        self.batch_generator = batch_generator\n",
    "\n",
    "        basedir = os.path.dirname(results_file)\n",
    "        if not os.path.exists(basedir):\n",
    "            os.makedirs(basedir)\n",
    "        self.results_file = results_file\n",
    "\n",
    "    @staticmethod\n",
    "    def IOU_loss(y_true, y_false):\n",
    "        def IOU_calc(y_true, y_false, smooth=1.):\n",
    "            y_true_f = y_true.flatten()\n",
    "            y_false_f = y_false.flatten()\n",
    "            intersection = np.sum(y_true_f * y_false_f)\n",
    "            union = np.sum(y_true_f) + np.sum(y_false_f) - intersection\n",
    "            return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "        return 1 - IOU_calc(y_true, y_false)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_batch, val_batch = self.batch_generator(VAL_BATCH)\n",
    "        train_imgs, train_masks = train_batch\n",
    "        val_imgs, val_masks = val_batch\n",
    "        train_results = self.model.predict(train_imgs)\n",
    "        val_results = self.model.predict(val_imgs)\n",
    "\n",
    "        # change categorical\n",
    "        train_losses = [\n",
    "            LossValidateCallback.IOU_loss(\n",
    "                mask_to_categorical(pair[0]), pair[1]\n",
    "            )\n",
    "            for pair in zip(train_masks, train_results)\n",
    "        ]\n",
    "        average_train_loss = np.average(train_losses)\n",
    "        std_train_loss = np.std(train_losses)\n",
    "\n",
    "        # change categorical\n",
    "        val_losses = [\n",
    "            LossValidateCallback.IOU_loss(\n",
    "                mask_to_categorical(pair[0]), pair[1]\n",
    "            )\n",
    "            for pair in zip(val_masks, val_results)\n",
    "        ]\n",
    "        average_val_loss = np.average(val_losses)\n",
    "        std_val_loss = np.std(val_losses)\n",
    "\n",
    "        # change categorical\n",
    "        train_size = len(train_masks)\n",
    "        batch_train_loss = LossValidateCallback.IOU_loss(\n",
    "            mask_to_categorical(train_masks, train_size), train_results\n",
    "        )\n",
    "\n",
    "        # change categorical\n",
    "        val_size = len(val_masks)\n",
    "        batch_val_loss = LossValidateCallback.IOU_loss(\n",
    "            mask_to_categorical(val_masks, val_size), val_results\n",
    "        )\n",
    "\n",
    "        eval_train_loss, _ = self.model.evaluate(\n",
    "            train_imgs, mask_to_categorical(train_masks, train_size)\n",
    "        )\n",
    "        eval_val_loss, _ = self.model.evaluate(\n",
    "            val_imgs, mask_to_categorical(val_masks, val_size)\n",
    "        )\n",
    "\n",
    "        text = '{0}, {1}, {2}, '.format(epoch, eval_train_loss, eval_val_loss)\n",
    "        text += '{0}, {1}, '.format(batch_train_loss, batch_val_loss)\n",
    "        text += '{0}, {1}, {2}, {3}\\n'.format(\n",
    "            average_train_loss, std_train_loss,\n",
    "            average_val_loss, std_val_loss\n",
    "        )\n",
    "        if not os.path.exists(self.results_file):\n",
    "            with open(self.results_file, 'w') as file:\n",
    "                columns = 'epoch, eval_train_loss, eval_validation_loss, '\n",
    "                columns += 'batch_train_loss, batch_val_loss, '\n",
    "                columns += 'batch_stats_train_avg_loss, batch_stats_train_std_loss, '\n",
    "                columns += 'batch_stats_val_avg_loss, batch_stats_val_std_loss\\n'\n",
    "                file.writelines(columns)\n",
    "            \n",
    "        with open(self.results_file, 'a') as file:\n",
    "            file.writelines(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, val_data_dir, results_file):\n",
    "    batch_gen = BatchGenerator(\n",
    "        data_dir=data_dir, val_data_dir=val_data_dir, batch_size=BATCH_SIZE\n",
    "    )\n",
    "    batch_gen.load_data()\n",
    "    model = Unet.model(IMG_ROWS, IMG_COLS)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=1e-4),\n",
    "        loss='categorical_crossentropy', #Unet.loss\n",
    "        metrics=[Unet.metric]\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath='deep_unet_batch_1_epoch_{epoch:02d}.hdf5',\n",
    "        mode='auto',\n",
    "        period=100\n",
    "    )\n",
    "    \n",
    "    def get_batch():\n",
    "        while True:\n",
    "            x, mask = next(batch_gen.train_batches)\n",
    "            mask = to_categorical(mask, 2)\n",
    "            mask = np.reshape(\n",
    "                mask,\n",
    "                (\n",
    "                    batch_gen.batch_size, IMG_COLS*IMG_ROWS, 2\n",
    "                )\n",
    "            )\n",
    "            yield x, mask\n",
    "    \n",
    "    model.fit_generator(\n",
    "        get_batch(),#batch_gen.train_batches,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=NB_EPOCHS,\n",
    "        callbacks=[\n",
    "            checkpoint,\n",
    "            LossValidateCallback(\n",
    "                batch_gen.generate_test_batch,\n",
    "                results_file\n",
    "            )\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset/dataset_256/'\n",
    "#data_overfit = 'dataset/data_val/'\n",
    "val_data_dir = 'dataset/val_dataset_256/'\n",
    "results_file = './results_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 31s - loss: 5.5188 - metric: -0.6816    \n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 19s - loss: 6.3817 - metric: -0.9384    \n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 18s - loss: 5.3939 - metric: -0.7783    \n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 19s - loss: 1.2730 - metric: 0.2362    \n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 19s - loss: 0.7374 - metric: 1.1602    \n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 21s - loss: 0.7110 - metric: 1.0929    \n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 20s - loss: 0.7013 - metric: 1.2354    \n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 18s - loss: 0.7123 - metric: 1.2107    \n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 19s - loss: 0.6902 - metric: 1.1903    \n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2s\n",
      "10/10 [==============================] - 1s\n",
      "10/10 [==============================] - 19s - loss: 0.7038 - metric: 1.1857    \n"
     ]
    }
   ],
   "source": [
    "train(data_dir, val_data_dir, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = BatchGenerator(\n",
    "    data_dir=data_dir, val_data_dir=val_data_dir, batch_size=BATCH_SIZE\n",
    ")\n",
    "batch_gen.load_data()\n",
    "model = Unet.model(IMG_ROWS, IMG_COLS)\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=1e-4),\n",
    "    loss=Unet.loss,\n",
    "    metrics=[Unet.metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch, val_batch = batch_gen.generate_test_batch(VAL_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU_loss(y_true, y_false):\n",
    "    def IOU_calc(y_true, y_false, smooth=1.):\n",
    "        y_true_f = y_true.flatten()\n",
    "        y_false_f = y_false.flatten()\n",
    "        intersection = np.sum(y_true_f * y_false_f)\n",
    "        return 2 * (intersection + smooth) / (np.sum(y_true_f) + np.sum(y_false_f) + smooth)\n",
    "\n",
    "    return 1 - IOU_calc(y_true, y_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_masks = train_batch\n",
    "val_imgs, val_masks = val_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 256, 256, 1) for Tensor 'reshape_15_target:0', which has shape '(?, ?, ?)'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-813eeda4c354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks=[\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#LossValidateCallback(*batch_gen.generate_test_batch(VAL_BATCH), results_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     ],\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1111\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1112\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 256, 256, 1) for Tensor 'reshape_15_target:0', which has shape '(?, ?, ?)'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "batch_gen = BatchGenerator(\n",
    "    data_dir=data_dir, val_data_dir=val_data_dir, batch_size=BATCH_SIZE\n",
    ")\n",
    "batch_gen.load_data()\n",
    "model = Unet.model(IMG_ROWS, IMG_COLS)\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=1e-4),\n",
    "    loss=Unet.loss,\n",
    "    metrics=[Unet.metric]\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='deep_unet_batch_1_epoch_{epoch:02d}.hdf5',\n",
    "    mode='auto',\n",
    "    period=100\n",
    ")\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_gen.train_batches,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        checkpoint#,\n",
    "        #LossValidateCallback(*batch_gen.generate_test_batch(VAL_BATCH), results_file)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.predict(train_imgs)\n",
    "val_results = model.predict(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 65536, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.shape\n",
    "val_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33173472978163765"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IOU_loss(train_masks, train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [IOU_loss(*pair) for pair in zip(train_masks, train_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34012692974544206"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3292281621428278,\n",
       " 0.45997652520413312,\n",
       " 0.40848355920392054,\n",
       " 0.21782842908632505,\n",
       " 0.34723014538066066,\n",
       " 0.13760194308455564,\n",
       " 0.36435066638504277,\n",
       " 0.44095448621814604,\n",
       " 0.24757870727572417,\n",
       " 0.44803667347308485]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34012692974544206"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10302512239756043"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = BatchGenerator(\n",
    "    data_dir=data_dir, val_data_dir=val_data_dir, batch_size=BATCH_SIZE\n",
    ")\n",
    "batch_gen.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = batch_gen.generate_test_batch(VAL_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    1.,    2.,    3.,    4.,    5.,    6.,    7.,    8.,\n",
       "          9.,   10.,   11.,   12.,   13.,   14.,   15.,   16.,   17.,\n",
       "         18.,   19.,   20.,   21.,   22.,   23.,   24.,   25.,   26.,\n",
       "         27.,   28.,   29.,   30.,   31.,   32.,   33.,   34.,   35.,\n",
       "         36.,   37.,   38.,   39.,   40.,   41.,   42.,   43.,   44.,\n",
       "         45.,   46.,   47.,   48.,   49.,   50.,   51.,   52.,   53.,\n",
       "         54.,   55.,   56.,   57.,   58.,   59.,   60.,   61.,   62.,\n",
       "         63.,   64.,   65.,   66.,   67.,   68.,   69.,   70.,   71.,\n",
       "         72.,   73.,   74.,   75.,   76.,   77.,   78.,   79.,   80.,\n",
       "         81.,   82.,   83.,   84.,   85.,   86.,   87.,   88.,   89.,\n",
       "         90.,   91.,   92.,   93.,   94.,   95.,   96.,   97.,   98.,\n",
       "         99.,  100.,  101.,  102.,  103.,  104.,  105.,  106.,  107.,\n",
       "        108.,  109.,  110.,  111.,  112.,  113.,  114.,  115.,  116.,\n",
       "        117.,  118.,  119.,  120.,  121.,  122.,  123.,  124.,  125.,\n",
       "        126.,  127.,  128.,  129.,  130.,  131.,  132.,  133.,  134.,\n",
       "        135.,  136.,  137.,  138.,  139.,  140.,  141.,  142.,  143.,\n",
       "        144.,  145.,  146.,  147.,  148.,  149.,  150.,  151.,  152.,\n",
       "        153.,  154.,  155.,  156.,  157.,  158.,  159.,  160.,  161.,\n",
       "        162.,  163.,  164.,  165.,  166.,  167.,  168.,  169.,  170.,\n",
       "        171.,  172.,  173.,  174.,  175.,  176.,  177.,  178.,  179.,\n",
       "        180.,  181.,  182.,  183.,  184.,  185.,  186.,  187.,  188.,\n",
       "        189.,  190.,  191.,  192.,  193.,  194.,  195.,  196.,  197.,\n",
       "        198.,  199.,  200.,  201.,  202.,  203.,  204.,  205.,  206.,\n",
       "        207.,  208.,  209.,  210.,  211.,  212.,  213.,  214.,  215.,\n",
       "        216.,  217.,  218.,  219.,  220.,  221.,  222.,  223.,  224.,\n",
       "        225.,  226.,  227.,  228.,  229.,  230.,  231.,  232.,  233.,\n",
       "        234.,  235.,  236.,  237.,  238.,  239.,  240.,  241.,  242.,\n",
       "        243.,  244.,  245.,  246.,  247.,  248.,  249.,  250.,  251.,\n",
       "        252.,  253.,  254.,  255.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(next(batch_gen.train_batches)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.batch_generator import BatchGenerator\n",
    "BATCH_SIZE = 1\n",
    "VAL_BATCH = 10\n",
    "IMG_ROWS, IMG_COLS = 256, 256\n",
    "NB_EPOCHS = 1001\n",
    "data_dir = 'dataset/dataset_256/'\n",
    "data_overfit = 'dataset/data_val/'\n",
    "val_data_dir = 'dataset/val_dataset_256/'\n",
    "results_file = './results_data.txt'\n",
    "batch_gen = BatchGenerator(\n",
    "    data_dir=data_overfit, val_data_dir=val_data_dir, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[ 244.,  245.,  240.],\n",
       "          [ 244.,  245.,  240.],\n",
       "          [ 245.,  246.,  241.],\n",
       "          ..., \n",
       "          [ 224.,  203.,  160.],\n",
       "          [ 240.,  229.,  209.],\n",
       "          [ 241.,  241.,  239.]],\n",
       " \n",
       "         [[ 244.,  245.,  240.],\n",
       "          [ 244.,  245.,  240.],\n",
       "          [ 245.,  246.,  241.],\n",
       "          ..., \n",
       "          [ 224.,  206.,  160.],\n",
       "          [ 226.,  218.,  195.],\n",
       "          [ 242.,  244.,  239.]],\n",
       " \n",
       "         [[ 244.,  245.,  240.],\n",
       "          [ 244.,  245.,  240.],\n",
       "          [ 245.,  246.,  241.],\n",
       "          ..., \n",
       "          [ 212.,  196.,  147.],\n",
       "          [ 215.,  209.,  183.],\n",
       "          [ 241.,  243.,  238.]],\n",
       " \n",
       "         ..., \n",
       "         [[ 246.,  241.,  199.],\n",
       "          [ 255.,  253.,  208.],\n",
       "          [ 249.,  245.,  200.],\n",
       "          ..., \n",
       "          [ 240.,  241.,  235.],\n",
       "          [ 246.,  245.,  243.],\n",
       "          [ 246.,  242.,  243.]],\n",
       " \n",
       "         [[ 254.,  249.,  207.],\n",
       "          [ 252.,  248.,  203.],\n",
       "          [ 246.,  242.,  197.],\n",
       "          ..., \n",
       "          [ 244.,  246.,  235.],\n",
       "          [ 242.,  241.,  237.],\n",
       "          [ 246.,  241.,  245.]],\n",
       " \n",
       "         [[ 233.,  230.,  185.],\n",
       "          [ 249.,  246.,  201.],\n",
       "          [ 253.,  249.,  204.],\n",
       "          ..., \n",
       "          [ 243.,  245.,  232.],\n",
       "          [ 243.,  242.,  238.],\n",
       "          [ 247.,  240.,  247.]]]], dtype=float32), array([[[[ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          ..., \n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.]],\n",
       " \n",
       "         [[ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          ..., \n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.]],\n",
       " \n",
       "         [[ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          ..., \n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          ..., \n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.]],\n",
       " \n",
       "         [[ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          ..., \n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.]],\n",
       " \n",
       "         [[ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          ..., \n",
       "          [ 0.],\n",
       "          [ 0.],\n",
       "          [ 0.]]]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(batch_gen.train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_gen._images_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
