{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2DTranspose,\n",
    "    Concatenate,\n",
    "    Convolution2D,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    MaxPooling2D,\n",
    "    ReLU,\n",
    "    Reshape,\n",
    "    ZeroPadding2D\n",
    ")\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "EPS = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    \n",
    "    def __init__(self, img_rows, img_cols):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.img_channels = 3\n",
    "        self.mask_channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.img_channels)\n",
    "        self.mask_shape = (self.img_rows, self.img_cols, self.mask_channels)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # build a generator\n",
    "        self.generator = _generator(64)\n",
    "        \n",
    "        # build discriminator\n",
    "        self.discriminator = self._discriminator(64)\n",
    "        self.discriminator.compile(\n",
    "            loss=DCGAN._discriminator_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # generator takes an image as an input and returns a mask\n",
    "        image = Input(shape=self.img_shape)\n",
    "        generated_mask = self.generator(inputs)\n",
    "    \n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # The discriminator takes generated masks with images as input and determines validity\n",
    "        combined_inputs_fake = Concatenate(axis=-1)([image, generated_mask])\n",
    "        \n",
    "        # return patch o 1's and 0's\n",
    "        discrim_fake = self.discriminator(combined_inputs_fake)\n",
    "        self.combined_model = Model(inputs=inputs, outputs=combined_inputs_fake)\n",
    "        self.combined_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=DCGAN._generator_loss(discrim_fake), # 'binary_crossentropy'\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def _generator(self, n_filters):\n",
    "        \"\"\"Generator method\"\"\"\n",
    "        inputs = Input(shape=self.img_shape)\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        output = Convolution2D(\n",
    "            filters=n_filters, kernel_size=(2, 2),\n",
    "            strides=(2, 2), padding='same'\n",
    "        )(inputs)\n",
    "        layers.append(output)\n",
    "        \n",
    "        layers_specs = [\n",
    "            n_filters * 2,\n",
    "            n_filters * 4,\n",
    "            n_filters * 8,\n",
    "            n_filters * 8,\n",
    "            n_filters * 8,\n",
    "            n_filters * 8,\n",
    "            n_filters * 8\n",
    "        ]\n",
    "        \n",
    "        for output_channels in layers_specs:\n",
    "            rectified_inputs = LeakyReLU(alpha=0.2)(layers[-1])\n",
    "            convolved = Convolution2D(\n",
    "                filters=output_channels, kernel_size=4,\n",
    "                strides=(2, 2), padding='same'\n",
    "            )(rectified_inputs)\n",
    "            output = BatchNormalization(\n",
    "                axis=-1, momentum=0.1, epsilon=1e-5, gamma_initializer=RandomNormal(1.0, 0.02)\n",
    "            )(convolved)\n",
    "            layers.append(output)\n",
    "            \n",
    "            \n",
    "        layers_specs = [\n",
    "            (n_filters * 8, 0.5),\n",
    "            (n_filters * 8, 0.5),\n",
    "            (n_filters * 8, 0.5),\n",
    "            (n_filters * 8, 0.0),\n",
    "            (n_filters * 4, 0.0),\n",
    "            (n_filters * 2, 0.0),\n",
    "            (n_filters, 0.0),\n",
    "        ]\n",
    "\n",
    "        num_encoder_layers = len(layers)\n",
    "        for dec_layer, (output_channels, dropout) in enumerate(layers_spec):\n",
    "            skip_layer = num_encoder_layers - dec_layer - 1\n",
    "            if dec_layer == 0:\n",
    "                # no skip connection for the first decoding layer\n",
    "                inputs = layers[-1]\n",
    "            else:\n",
    "                inputs = Concatenate(axis=-1)([layers[-1], layers[skip_layer]])\n",
    "            rectified_output = ReLU()(inputs)\n",
    "            output = Conv2DTranspose(\n",
    "                filters=output_channels, kernel_size=4, strides=(2, 2),\n",
    "                padding='same', kernel_initializer=RandomNormal(0.0, 0.02)\n",
    "            )(rectified_output)\n",
    "            output = BatchNormalization(\n",
    "                axis=-1, momentum=0.1,\n",
    "                epsilon=1e-5, gamma_initializer=RandomNormal(1.0, 0.02)\n",
    "            )(output)\n",
    "            \n",
    "            if dropout > 0:\n",
    "                output = Dropout(dropout)(output)\n",
    "            \n",
    "            layers.append(output)\n",
    "                \n",
    "        inputs = Concatenate(axis=-1)([layers[-1], layers[0]])\n",
    "        rectified_inputs = ReLU()(inputs)\n",
    "        output = Conv2DTranspose(\n",
    "                filters=self.mask_channels, kernel_size=4, strides=(2, 2),\n",
    "                padding='same', kernel_initializer=RandomNormal(0.0, 0.02)\n",
    "        )(rectified_inputs)\n",
    "        output = Activation('tanh')(rectified_inputs)\n",
    "        layers.append(output)\n",
    "        \n",
    "        return Model(inputs=inputs, outputs=layers[-1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _generator_loss(predict_fake,\n",
    "                        gan_weight=1.0,\n",
    "                        l1_weight=100):\n",
    "        # predict_fake => 1\n",
    "        # abs(targets - outputs) => 0\n",
    "        gen_loss_gan = K.mean(-K.log(predict_fake + EPS))\n",
    "        def loss(targets, generated):\n",
    "            gen_loss_l1 = K.mean(K.abs(targets - generated))\n",
    "            gen_loss = gen_loss_gan * gan_weight + gen_loss_l1 * l1_weight\n",
    "            return gen_loss\n",
    "        return loss#gen_loss_gan, gen_loss_l1, gen_loss\n",
    "        \n",
    "    @staticmethod\n",
    "    def _discriminator(self, n_filters):\n",
    "        n_layers = 3\n",
    "        layers = []\n",
    "        image = Input(shape=self.img_shape)\n",
    "        mask = Input(shape=self.mask_shape)\n",
    "        \n",
    "        # 2x [batch, height, width, in_channels] =>\n",
    "        #    [batch, height, width, in_channels * 2]\n",
    "        combined_inputs = Concatenate(axis=-1)([image, mask])\n",
    "        padded = ZeroPadding2D(\n",
    "            padding=((1,1), (1, 1)), data_format='channels_last')\n",
    "        (combined_inputs)\n",
    "        output = Convolution2D(\n",
    "            filters=n_filters, kernel_size=4,\n",
    "            strides=(2, 2), padding='valid',\n",
    "            kernel_initializer=RandomNormal(0, 0.02)\n",
    "        )(padded)\n",
    "        output = LeakyReLU(alpha=0.2)(output)\n",
    "        layers.append(output)\n",
    "        \n",
    "        # layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]\n",
    "        # layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]\n",
    "        # layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            output_channels = n_filters * min(2 ** (i + 1), 8)\n",
    "            stride = 1 if i == n_layers - 1 else 2\n",
    "            output = Convolution2D(\n",
    "                filters=output_channels, kernel_size=4,\n",
    "                strides=(stride, stride), padding='valid',\n",
    "                kernel_initializer=RandomNormal(0, 0.02)\n",
    "            )(layers[-1])\n",
    "            output = BatchNormalization(\n",
    "                axis=-1, epsilon=1e-5, momentum=0.1, gamma_initializer=RandomNormal(1.0, 0.02)\n",
    "            )(output)\n",
    "            output = LeakyReLU(alpha=0.2)(output)\n",
    "            layers.append(output)\n",
    "        \n",
    "        output = Convolution2D(\n",
    "                filters=1, kernel_size=4,\n",
    "                strides=(1, 1), padding='valid',\n",
    "                kernel_initializer=RandomNormal(0, 0.02),\n",
    "                activation='sigmoid'\n",
    "            )(layers[-1])\n",
    "        layers.append(output)\n",
    "        \n",
    "        return Model(inputs=combined_inputs, outputs=layers[-1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _discriminator_loss(predict_real, predict_fake):\n",
    "        # minimizing -tf.log will try to get inputs to 1\n",
    "        # predict_real => 1\n",
    "        # predict_fake => 0\n",
    "        return K.mean(\n",
    "            -(K.log(predict_real + EPS) + K.log(1 - predict_fake + EPS))\n",
    "        )\n",
    "\n",
    "    def train(self, train_batches, batch_size, callbacks, nb_epochs, steps_per_epoch=1e3, initial_epoch):\n",
    "        \"\"\"Model training method\"\"\"\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        for epoch in range(nb_epochs):\n",
    "            for step in range(steps_per_epoch)\n",
    "                # -------------------\n",
    "                # Train discriminator\n",
    "                # -------------------\n",
    "                img, mask = next(train_batches)\n",
    "                generated = self.generator(img)\n",
    "\n",
    "                # train discriminator where real-like classified images are 1's\n",
    "                # and fake-like ones are 0's\n",
    "                discrim_loss_real = self.discriminator.train_on_batch(\n",
    "                    np.concatenate([img, mask], axis=-1), valid\n",
    "                )\n",
    "                d_loss_fake = self.discriminator.train_on_batch(\n",
    "                    np.concatenate([img, generated], axis=-1), fake\n",
    "                )\n",
    "\n",
    "                # ---------------\n",
    "                # Train generator\n",
    "                # ---------------\n",
    "                self.combined_model.train_on_batch(\n",
    "                    img, valid\n",
    "                )\n",
    "                \n",
    "            \n",
    "\n",
    "        model.fit_generator(\n",
    "            train_batches,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epochs,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def metric(y_true, y_false, smooth=1.):\n",
    "        y_true_f = y_true.flatten()\n",
    "        y_false_f = y_false.flatten()\n",
    "        intersection = np.sum(y_true_f * y_false_f)\n",
    "        union = np.sum(y_true_f) + np.sum(y_false_f) - intersection\n",
    "        return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
